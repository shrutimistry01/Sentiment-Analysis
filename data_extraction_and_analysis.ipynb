{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "495348dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\91836\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\91836\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd \n",
    "import openpyxl\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27f6df4",
   "metadata": {},
   "source": [
    "# Data extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a964f4",
   "metadata": {},
   "source": [
    "### Extracting data from input file url and saving it into url_id.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc8653b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'Input.xlsx'\n",
    "data = pd.ExcelFile(file)\n",
    "df = data.parse('Sheet1')\n",
    "\n",
    "ps = openpyxl.load_workbook('Input.xlsx')\n",
    "sheet = ps['Sheet1']\n",
    "no_of_articles=0\n",
    "for row in range(2, sheet.max_row + 1):\n",
    "    url = sheet['B' + str(row)].value\n",
    "    url_id = int(sheet['A' + str(row)].value)\n",
    "    # Each value in a cell is represented by a column letter and a row number. So #the first element in the sheet is B1, next column C1 and so on. This enables #to iterate over the entire cells.\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101 Firefox/60.0\"}\n",
    "    page = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    try:\n",
    "        title=soup.find('h1',class_=\"entry-title\")\n",
    "        title=title.text.replace('\\n',\"\")\n",
    "    except AttributeError:\n",
    "        title=\"\"\n",
    "    try:\n",
    "        content=soup.findAll(attrs={'class':'td-post-content'})\n",
    "        content=content[0].text.replace('\\n',\"\")\n",
    "    except (AttributeError,IndexError) as e :\n",
    "        content=\"\"\n",
    "    no_of_articles+=1\n",
    "    f = open(\"articles/{}.txt\".format(url_id),\"w\", encoding=\"utf-8\")\n",
    "    f.write(title+'\\n')\n",
    "    f.write(content)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0521ee",
   "metadata": {},
   "source": [
    "\n",
    "# Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6c058dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting all the stopwords\n",
    "\n",
    "with open(\"StopWords/StopWords_Auditor.txt\",\"r\") as s1,open(\"StopWords/StopWords_Currencies.txt\",\"r\") as s2,open(\"StopWords/StopWords_DatesandNumbers.txt\",\"r\") as s3,open(\"StopWords/StopWords_Generic.txt\",\"r\") as s4,open(\"StopWords/StopWords_GenericLong.txt\",\"r\") as s5,open(\"StopWords/StopWords_Geographic.txt\",\"r\") as s6,open(\"StopWords/StopWords_Names.txt\",\"r\") as s7:\n",
    "    s1,s2,s3,s4,s5,s6,s7 = s1.read(),s2.read(),s3.read(),s4.read(),s5.read(),s6.read(),s7.read()\n",
    "    s = s1+s2+s3+s4+s5+s6+s7\n",
    "stop_words = s.split(\"\\n\")\n",
    "\n",
    "#Creating a dictionary of Positive and Negative words\n",
    "\n",
    "with open(\"C:/Users/91836/data_science_proj/black cofer/MasterDictionary/positive-words.txt\",\"r\") as pos:\n",
    "    positive_dictionary = pos.read().split(\"\\n\") \n",
    "    \n",
    "with open(\"C:/Users/91836/data_science_proj/black cofer/MasterDictionary/negative-words.txt\",\"r\") as neg:\n",
    "    negative_dictionary = neg.read().split(\"\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847990b1",
   "metadata": {},
   "source": [
    "### Useful functions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b08f622a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_stopwords(words, stop_words):\n",
    "        return [word for word in words if word not in stop_words]\n",
    "\n",
    "def count(dictionary, words):\n",
    "    count = 0\n",
    "    for x in words:\n",
    "        if(x in dictionary):\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "def polarity(positive_score, negative_score):\n",
    "    return ((positive_score - negative_score)/((positive_score + negative_score)+ 0.000001))\n",
    "\n",
    "def subjectivity(positive_score, negative_score, num_words):\n",
    "    return ((positive_score+negative_score)/(num_words+ 0.000001))\n",
    "\n",
    "def syllable_count(word):\n",
    "    if(len(word) > 2 and (word[-2:] == 'es' or word[-2:] == 'ed')):\n",
    "        return 0\n",
    "    count=0\n",
    "    vowel=['a','e','i','o','u']\n",
    "    for x in word:\n",
    "        if x in vowel:\n",
    "            count+=1\n",
    "    return count \n",
    "    \n",
    "def complex_words(words):\n",
    "    num_complexword=0\n",
    "    for word in words:\n",
    "         if(syllable_count(word)>2):\n",
    "                        num_complexword = num_complexword+1\n",
    "    return num_complexword\n",
    "\n",
    "def personal_pronouns(text):\n",
    "    pronounList = re.compile(r'\\b(I|we|my|ours|(?-i:us))\\b',re.I)\n",
    "    pronouns = pronounList.findall(text)\n",
    "    return(len(pronouns))      \n",
    "\n",
    "def clean_words(text):\n",
    "    #Remove Punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) \n",
    "    tokens= word_tokenize(text)\n",
    "    \n",
    "    #removing the stop words (using stopwords class of nltk package)\n",
    "    my_stop_words = stopwords.words('english')\n",
    "    final_words = [token for token in tokens if  token not in my_stop_words]\n",
    "    \n",
    "    return(len(final_words))\n",
    "\n",
    "def file_not_empty(file_name):\n",
    "    return os.path.exists(file_name) and os.stat(file_name).st_size > 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f865c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dataframe\n",
    "df_cols=[\"URL_ID\",\"URL\",\"POSITIVE SCORE\",\"NEGATIVE SCORE\",\"POLARITY SCORE\",\"SUBJECTIVITY SCORE\",\"AVG SENTENCE LENGTH\",\"PERCENTAGE OF COMPLEX WORDS\",\"FOG INDEX\",\"AVG NUMBER OF WORDS PER SENTENCE\",\"COMPLEX WORD COUNT\",\"WORD COUNT\",\"SYLLABLE PER WORD\",\"PERSONAL PRONOUNS\",\"AVG WORD LENGTH\"]\n",
    "df = pd.DataFrame(columns=df_cols)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9ecf6b",
   "metadata": {},
   "source": [
    "### Scraping .txt files for text analysis of each article\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31f4b652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.txt is empty\n",
      "57.txt is empty\n",
      "144.txt is empty\n"
     ]
    }
   ],
   "source": [
    "row=2\n",
    "for i in range(no_of_articles):\n",
    "    \n",
    "    #All input variables in “Input.xlsx”\n",
    "    url_id = int(sheet['A' + str(row)].value)\n",
    "    url = sheet['B' + str(row)].value\n",
    "    row+=1\n",
    "    \n",
    "    file_path='articles/{}.txt'.format(url_id)\n",
    "    \n",
    "    if(file_not_empty(file_path)):\n",
    "        \n",
    "        #Extracting article from saved files \n",
    "        txtFile=open(file_path,'r',encoding=\"utf-8\")\n",
    "        wholeF=txtFile.readlines()\n",
    "        title=wholeF[0]\n",
    "        content=wholeF[1]\n",
    "\n",
    "        #Tokenization\n",
    "        word_tokens = word_tokenize(content)\n",
    "\n",
    "        #removing stop words\n",
    "        words = remove_stopwords(word_tokens, stop_words)\n",
    "        num_words = len(words)\n",
    "\n",
    "\n",
    "        sentences = sent_tokenize(content)\n",
    "        num_sentences = len(sentences)\n",
    "\n",
    "\n",
    "        #Extracting Derived variables\n",
    "\n",
    "        positive_score = count(positive_dictionary, words)\n",
    "\n",
    "        negative_score = count(negative_dictionary, words)\n",
    "\n",
    "        polarity_score = polarity(positive_score, negative_score)\n",
    "\n",
    "        subjectivity_score = subjectivity(positive_score, negative_score, num_words)\n",
    "\n",
    "\n",
    "        #Analysis of Readability\n",
    "\n",
    "        average_sentence_length = num_words/num_sentences\n",
    "\n",
    "        num_complexwords= complex_words(words)\n",
    "        percentage_complexwords = (num_complexwords/num_words)\n",
    "\n",
    "        fog_index =  0.4*(average_sentence_length + percentage_complexwords)\n",
    "\n",
    "\n",
    "        #Average Number of Words Per Sentence\n",
    "\n",
    "        avg_no_of_words_per_sentence = num_words/num_sentences\n",
    "\n",
    "\n",
    "        #Word Count of  word without stopwords and punctutaion\n",
    "        word_count = clean_words(content)\n",
    "\n",
    "        # SYLLABLE PER WORD\n",
    "        total_syllable_count=0\n",
    "        for word in words:\n",
    "            total_syllable_count+= syllable_count(word)\n",
    "\n",
    "        syllable_per_word = total_syllable_count/num_words\n",
    "\n",
    "        # Personal Pronouns\n",
    "        pronouns= personal_pronouns(content)  \n",
    "\n",
    "        # Average Word Length    \n",
    "        average_word_length=sum(len(word) for word in words)/num_words\n",
    "\n",
    "        data=[url_id,url,positive_score,negative_score,polarity_score,subjectivity_score,average_sentence_length,percentage_complexwords,fog_index,avg_no_of_words_per_sentence,num_complexwords,word_count,syllable_per_word,pronouns,average_word_length]\n",
    "        df.loc[i]=data\n",
    "    else:\n",
    "        print(\"{}.txt is empty\".format(url_id))\n",
    "        data=[url_id,url,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "        df.loc[i]=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "582ad0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>62</td>\n",
       "      <td>31</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.074940</td>\n",
       "      <td>23.415094</td>\n",
       "      <td>0.406124</td>\n",
       "      <td>9.528487</td>\n",
       "      <td>23.415094</td>\n",
       "      <td>504</td>\n",
       "      <td>1171</td>\n",
       "      <td>2.040290</td>\n",
       "      <td>1</td>\n",
       "      <td>6.514102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>55</td>\n",
       "      <td>36</td>\n",
       "      <td>0.208791</td>\n",
       "      <td>0.103881</td>\n",
       "      <td>12.882353</td>\n",
       "      <td>0.262557</td>\n",
       "      <td>5.257964</td>\n",
       "      <td>12.882353</td>\n",
       "      <td>230</td>\n",
       "      <td>810</td>\n",
       "      <td>1.521689</td>\n",
       "      <td>7</td>\n",
       "      <td>5.294521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>65</td>\n",
       "      <td>34</td>\n",
       "      <td>0.313131</td>\n",
       "      <td>0.088078</td>\n",
       "      <td>16.776119</td>\n",
       "      <td>0.375445</td>\n",
       "      <td>6.860626</td>\n",
       "      <td>16.776119</td>\n",
       "      <td>422</td>\n",
       "      <td>1036</td>\n",
       "      <td>1.936833</td>\n",
       "      <td>3</td>\n",
       "      <td>6.258007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>56</td>\n",
       "      <td>22</td>\n",
       "      <td>0.435897</td>\n",
       "      <td>0.083601</td>\n",
       "      <td>11.961538</td>\n",
       "      <td>0.317256</td>\n",
       "      <td>4.911518</td>\n",
       "      <td>11.961538</td>\n",
       "      <td>296</td>\n",
       "      <td>964</td>\n",
       "      <td>1.787781</td>\n",
       "      <td>17</td>\n",
       "      <td>5.673098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>49</td>\n",
       "      <td>23</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.063158</td>\n",
       "      <td>16.764706</td>\n",
       "      <td>0.301754</td>\n",
       "      <td>6.826584</td>\n",
       "      <td>16.764706</td>\n",
       "      <td>344</td>\n",
       "      <td>1052</td>\n",
       "      <td>1.739474</td>\n",
       "      <td>16</td>\n",
       "      <td>5.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>146</td>\n",
       "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>16.432432</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>6.699289</td>\n",
       "      <td>16.432432</td>\n",
       "      <td>192</td>\n",
       "      <td>566</td>\n",
       "      <td>1.824013</td>\n",
       "      <td>9</td>\n",
       "      <td>6.245066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>147</td>\n",
       "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.046018</td>\n",
       "      <td>23.061224</td>\n",
       "      <td>0.293805</td>\n",
       "      <td>9.342012</td>\n",
       "      <td>23.061224</td>\n",
       "      <td>332</td>\n",
       "      <td>998</td>\n",
       "      <td>1.644248</td>\n",
       "      <td>2</td>\n",
       "      <td>5.572566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>148</td>\n",
       "      <td>https://insights.blackcoffer.com/big-data-anal...</td>\n",
       "      <td>26</td>\n",
       "      <td>44</td>\n",
       "      <td>-0.257143</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>13.311475</td>\n",
       "      <td>0.359606</td>\n",
       "      <td>5.468433</td>\n",
       "      <td>13.311475</td>\n",
       "      <td>292</td>\n",
       "      <td>713</td>\n",
       "      <td>1.865764</td>\n",
       "      <td>2</td>\n",
       "      <td>5.697044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>149</td>\n",
       "      <td>https://insights.blackcoffer.com/business-anal...</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.071895</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>0.437908</td>\n",
       "      <td>10.375163</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>201</td>\n",
       "      <td>432</td>\n",
       "      <td>2.198257</td>\n",
       "      <td>0</td>\n",
       "      <td>6.989107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>150</td>\n",
       "      <td>https://insights.blackcoffer.com/challenges-an...</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>-0.117647</td>\n",
       "      <td>0.101040</td>\n",
       "      <td>10.854839</td>\n",
       "      <td>0.307578</td>\n",
       "      <td>4.464967</td>\n",
       "      <td>10.854839</td>\n",
       "      <td>207</td>\n",
       "      <td>619</td>\n",
       "      <td>1.824666</td>\n",
       "      <td>8</td>\n",
       "      <td>5.864785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    URL_ID                                                URL POSITIVE SCORE  \\\n",
       "0       37  https://insights.blackcoffer.com/ai-in-healthc...             62   \n",
       "1       38  https://insights.blackcoffer.com/what-if-the-c...             55   \n",
       "2       39  https://insights.blackcoffer.com/what-jobs-wil...             65   \n",
       "3       40  https://insights.blackcoffer.com/will-machine-...             56   \n",
       "4       41  https://insights.blackcoffer.com/will-ai-repla...             49   \n",
       "..     ...                                                ...            ...   \n",
       "109    146  https://insights.blackcoffer.com/blockchain-fo...             20   \n",
       "110    147  https://insights.blackcoffer.com/the-future-of...             40   \n",
       "111    148  https://insights.blackcoffer.com/big-data-anal...             26   \n",
       "112    149  https://insights.blackcoffer.com/business-anal...             29   \n",
       "113    150  https://insights.blackcoffer.com/challenges-an...             30   \n",
       "\n",
       "    NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  AVG SENTENCE LENGTH  \\\n",
       "0               31        0.333333            0.074940            23.415094   \n",
       "1               36        0.208791            0.103881            12.882353   \n",
       "2               34        0.313131            0.088078            16.776119   \n",
       "3               22        0.435897            0.083601            11.961538   \n",
       "4               23        0.361111            0.063158            16.764706   \n",
       "..             ...             ...                 ...                  ...   \n",
       "109             28       -0.166667            0.078947            16.432432   \n",
       "110             12        0.538462            0.046018            23.061224   \n",
       "111             44       -0.257143            0.086207            13.311475   \n",
       "112              4        0.757576            0.071895            25.500000   \n",
       "113             38       -0.117647            0.101040            10.854839   \n",
       "\n",
       "     PERCENTAGE OF COMPLEX WORDS  FOG INDEX  AVG NUMBER OF WORDS PER SENTENCE  \\\n",
       "0                       0.406124   9.528487                         23.415094   \n",
       "1                       0.262557   5.257964                         12.882353   \n",
       "2                       0.375445   6.860626                         16.776119   \n",
       "3                       0.317256   4.911518                         11.961538   \n",
       "4                       0.301754   6.826584                         16.764706   \n",
       "..                           ...        ...                               ...   \n",
       "109                     0.315789   6.699289                         16.432432   \n",
       "110                     0.293805   9.342012                         23.061224   \n",
       "111                     0.359606   5.468433                         13.311475   \n",
       "112                     0.437908  10.375163                         25.500000   \n",
       "113                     0.307578   4.464967                         10.854839   \n",
       "\n",
       "    COMPLEX WORD COUNT WORD COUNT  SYLLABLE PER WORD PERSONAL PRONOUNS  \\\n",
       "0                  504       1171           2.040290                 1   \n",
       "1                  230        810           1.521689                 7   \n",
       "2                  422       1036           1.936833                 3   \n",
       "3                  296        964           1.787781                17   \n",
       "4                  344       1052           1.739474                16   \n",
       "..                 ...        ...                ...               ...   \n",
       "109                192        566           1.824013                 9   \n",
       "110                332        998           1.644248                 2   \n",
       "111                292        713           1.865764                 2   \n",
       "112                201        432           2.198257                 0   \n",
       "113                207        619           1.824666                 8   \n",
       "\n",
       "     AVG WORD LENGTH  \n",
       "0           6.514102  \n",
       "1           5.294521  \n",
       "2           6.258007  \n",
       "3           5.673098  \n",
       "4           5.684211  \n",
       "..               ...  \n",
       "109         6.245066  \n",
       "110         5.572566  \n",
       "111         5.697044  \n",
       "112         6.989107  \n",
       "113         5.864785  \n",
       "\n",
       "[114 rows x 15 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984f85cf",
   "metadata": {},
   "source": [
    "### Saving the computed variables in output.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8c2f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Output.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37ca85f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d151efe57688b556b2f23e92df935925d63831cfe5c4e5687bed9a1a2c9aa16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
